<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0"><channel><title>All Posts - blog.pavelsklenar.com</title><link>https://blog.pavelsklenar.com/posts/</link><description>All Posts | blog.pavelsklenar.com</description><generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>sklenar.pav@gmail.com (Pavel Sklenar)</managingEditor><webMaster>sklenar.pav@gmail.com (Pavel Sklenar)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sun, 12 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.pavelsklenar.com/posts/" rel="self" type="application/rss+xml"/><item><title>Creating two node Nomad cluster</title><link>https://blog.pavelsklenar.com/two-node-nomad-cluster/</link><pubDate>Sun, 12 Dec 2021 00:00:00 +0000</pubDate><author>sklenar.pav@gmail.com</author><dc:creator>Pavel Sklenar</dc:creator><guid>https://blog.pavelsklenar.com/two-node-nomad-cluster/</guid><description>Nomad is an interesting alternative to Kubernetes. As authors of Nomad say, it is a suplement to Kubernetes and offers some great features.
Here you can find a guide on how to create a fresh Nomad cluster with two nodes. The first node acts as a server and client, the second node acts as a client only. I know this architecture is not recommended for production purposes, but I would like to test it only.</description></item><item><title>Extend local network to cloud with Nebula</title><link>https://blog.pavelsklenar.com/extend-local-network-to-cloud-with-nebula/</link><pubDate>Sun, 12 Dec 2021 00:00:00 +0000</pubDate><author>sklenar.pav@gmail.com</author><dc:creator>Pavel Sklenar</dc:creator><guid>https://blog.pavelsklenar.com/extend-local-network-to-cloud-with-nebula/</guid><description>Nebula Network Nebula is a scalable overlay networking tool with a focus on performance, simplicity, and security. It lets you seamlessly connect computers anywhere in the world. This post is about extending the local network by another server running anywhere in the world, everything secured by the Nebula network.
Devices on the local network should be able to access devices on the Nebula network and some devices need to access devices on the local network as well.</description></item><item><title>Transfer data between two systems using Azure functions</title><link>https://blog.pavelsklenar.com/azure-functions-system-integration/</link><pubDate>Fri, 22 Oct 2021 00:00:00 +0000</pubDate><author>sklenar.pav@gmail.com</author><dc:creator>Pavel Sklenar</dc:creator><guid>https://blog.pavelsklenar.com/azure-functions-system-integration/</guid><description>Introduction This simple demo shows possible integration between two systems (system A and system B) using Azure Functions.
Note The full example with all resources could be found here on GitHub. The architecture constraints:
All updates from the system A must be transfered into the system B The system A is listening on HTTP with REST API The system B is listening on HTTP with REST API The system B is not fully compatible in message definitions, so field mapping must be used The mapping must be saved in DB (I chose CosmosDB) Due to missing push notification in the system A, its API must be periodically checked The system B may be occasionally offline, so some type of persistent bus should be used.</description></item><item><title>Creating Azure Red Hat OpenShift 4 cluster</title><link>https://blog.pavelsklenar.com/iaac-aro/</link><pubDate>Thu, 23 Sep 2021 00:00:00 +0000</pubDate><author>sklenar.pav@gmail.com</author><dc:creator>Pavel Sklenar</dc:creator><guid>https://blog.pavelsklenar.com/iaac-aro/</guid><description>You can find here the guide:
how to create an Azure Red Hat OpenShift 4 (ARO) cluster, how to setup connectivity to the new ARO cluster, how to deploy an example application. Note The full example with all resources could be found here on GitHub. Create Azure Red Hat OpenShift 4 (ARO) cluster Prepare environment Set the correct subsription:
az account set -s TestingSubscription The file .</description></item><item><title>Jenkins - Creating Dynamic Project Folders with Job DSL</title><link>https://blog.pavelsklenar.com/jenkins-creating-dynamic-project-folders-with-job-dsl/</link><pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate><author>sklenar.pav@gmail.com</author><dc:creator>Pavel Sklenar</dc:creator><guid>https://blog.pavelsklenar.com/jenkins-creating-dynamic-project-folders-with-job-dsl/</guid><description>This post is about the dynamic creating of project folders in Jenkins using Job DSL Plugin. The newly created project folders will be accessible by a specific group or user only, so you are able to use your Jenkins instance by multiple teams and each team will have their own folder for their projects.
Before we can start, the following plugins must be installed:
Matrix Authorization Strategy Job DSL Plugin Setting Up Correct Authorization Type The first step is related to set up a correct authorization type in the Configure Global Security menu:</description></item><item><title>Vulnerability Scan as part of Continuous Integration</title><link>https://blog.pavelsklenar.com/vulnerability-scan-as-part-of-continuous-integration/</link><pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate><author>sklenar.pav@gmail.com</author><dc:creator>Pavel Sklenar</dc:creator><guid>https://blog.pavelsklenar.com/vulnerability-scan-as-part-of-continuous-integration/</guid><description>Have you ever image how many vulnerabilities exist in your applications since it was created? And how many of them comes from its dependencies?
The high secure environments require to perform regularly checks to discover any new vulnerability issue in your application. These checks can be done manually, but it may take a lot of time, especially if you are using the current frameworks (e.g. Spring Boot) with many and many transitive dependencies.</description></item><item><title>Spring Boot: Run and Build in Docker</title><link>https://blog.pavelsklenar.com/spring-boot-run-and-build-in-docker/</link><pubDate>Sun, 16 Dec 2018 00:00:00 +0000</pubDate><author>sklenar.pav@gmail.com</author><dc:creator>Pavel Sklenar</dc:creator><guid>https://blog.pavelsklenar.com/spring-boot-run-and-build-in-docker/</guid><description>It exists many “Docker for Java developers” guides, but most of them does not take care of small and efficient Docker images.
I have combined many resources how to make a simple and fast Docker image containing any of Spring Boot like application.
My goals:
Create a single and portable Dockerfile (as general as possible). Make Maven build inside Docker (no need to have Maven locally). Don&amp;rsquo;t download any Maven dependencies repeatedly, if no changes in pom.</description></item><item><title>Securing REST APIs with Client Certificates</title><link>https://blog.pavelsklenar.com/securing-rest-api-with-client-certificate/</link><pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate><author>sklenar.pav@gmail.com</author><dc:creator>Pavel Sklenar</dc:creator><guid>https://blog.pavelsklenar.com/securing-rest-api-with-client-certificate/</guid><description>This post is about an example of securing REST API with a client certificate (a.k.a. X.509 certificate authentication).
In other words, a client verifies a server according to its certificate and the server identifies that client according to a client certificate (so-called the mutual authentication).
In connection with Spring Security, we will be able to perform some additional authentication and authorization.
Technologies used:
Spring Boot 2.0.5.RELEASE Spring Web + Security 5.</description></item><item><title>TCP Port Scanner Example using Spring Shell</title><link>https://blog.pavelsklenar.com/tcp-port-scanner-using-spring-shell/</link><pubDate>Tue, 18 Sep 2018 00:00:00 +0000</pubDate><author>sklenar.pav@gmail.com</author><dc:creator>Pavel Sklenar</dc:creator><guid>https://blog.pavelsklenar.com/tcp-port-scanner-using-spring-shell/</guid><description>This post is about using Spring Shell to make a simple application for scanning open TCP ports.
Technologies used:
Spring Boot 2.0.5.RELEASE Spring Shell 2.0.1.RELEASE Quick Overview:
Final Project Structure Creating a new base Spring Boot project Needs for parallelism How check whether a port is open? Integrating with Spring Shell How it works Final Project Structure The final project structure" The final project structure</description></item><item><title>How To Create PKCS #12 For Your Application</title><link>https://blog.pavelsklenar.com/how-to-create-pkcs-12-for-your-application/</link><pubDate>Sat, 18 Aug 2018 00:00:00 +0000</pubDate><author>sklenar.pav@gmail.com</author><dc:creator>Pavel Sklenar</dc:creator><guid>https://blog.pavelsklenar.com/how-to-create-pkcs-12-for-your-application/</guid><description>This post is about creating PKCS #12 to serve e.g. your content via HTTPS in your application itself or in another web container (such a Tomcat or another application server).
The PKCS #12 format is a binary format for storing cryptography objects. It usually contains the server certificate, any intermediate certificates (i.e. chain of trust), and the private key, all of them in a single file. A PKCS #12 file may be encrypted and signed.</description></item></channel></rss>